---
date: "2020-12-13T19:01:49+08:00"
title: "操作系统：主存"
authors: Nicholas Zhan
categories:
  - OS
tags:
  - OS
draft: false
toc: true
mathjax: true
---
## 物理地址与虚拟地址

*Computer Systems: A Programmer's Perspective* 一书中是这么描述物理地址的：计算机系统的主存被组织成一个由 `M` 个连续的字节大小的单元组成的数组，每个字节都有一个唯一的 **物理地址（Physical Address）**。也就是说，物理地址表示的是数据在主存中的物理位置。

早期的计算机中没有存储器抽象，每一个程序都直接访问物理地址，我们把 CPU 直接访问物理地址的这种寻址方式称为 **物理寻址(physical addressing)**。而 **虚拟地址(Virtual Address)** 是 CPU 在程序运行期间生成的一个地址，虚拟地址又叫**逻辑地址（Logical Address）**，**虚拟寻址（virtual addressing）** 是现代计算机所采用的寻址形式。**内存管理单元（Memory Management Unit, MMU）** 是 CPU 上的一个专用硬件，负责完成虚拟地址到物理地址的映射，这个过程叫做 **地址翻译（address translation）**。

![物理寻址与虚拟寻址](/images/operating_systems/memory_management/physical-addressing-and-virtual-addressing.png)

上图左边展示了一个物理寻址的示例，该示例展示了一条指令，它从物理地址 4 开始读取 4 个字节。当 CPU 执行这条指令时，会生成一个物理地址，CPU 通过内存总线将物理地址 4 传给主存。主存从物理地址 4 开始取出 4 个字节，并将它返给 CPU。而上图右边展现了一个虚拟寻址的例子，CPU 在执行指令时拿到的是一个虚拟地址 4100，它将这个虚拟地址传给 MMU，MMU 将这个虚拟地址映射到物理地址 4，然后将物理地址传给主存。

使用物理地址存在的一些问题：首先，用户程序可以访问任意地址，容易破坏操作系统。此外，使用物理地址会让同时运行多个程序变得很困难。

## 地址空间

要使多个应用程序同时处于内存中并且不互相影响，就需要解决两个问题：保护和重定位。**地址空间（address space）** 是一个地址集合，进程可用它在内存中寻址。每个进程都有一个自己独立的地址空间，一般情况下，进程各自的地址空间是相互独立的。

计算机的物理内存总是有限的，而所有进程所需的 RAM 总量通常比内存要大得多。有两种处理内存超载的通用方法：**交换（swapping）** 和 **虚拟内存（virtual memory）**。交换技术将一个进程完整地载入内存，运行一段时间，然后再将它存回硬盘。空闲进程主要存储在硬盘上，所以只要它们不运行就不会占用内存。虚拟内存能够使程序在只有一部分被载入内存的情况下运行。

## 空闲内存管理

操作系统必须对动态分配的内存进行管理。追踪内存的使用情况的方式主要有两种：**位图（bitmap）** 和 **空闲链表（free list）**。

### 位图

使用位图时，内存被划分为分配单元（分配单元的大小根据实际情况确定，小到几个字，大到几千个字节），每个分配单元对应于位图中的一位。位图中用 1 表示空闲，0 表示已被使用；也可以用 0 表示空闲，1 表示已使用。因此，位图又称 **位向量（bit vector）**。

例如，假设内存中前 32 个分配单元的第2、3、4、5、8、9、10、11、12、13、17、18、25、26和27个分配单元是空闲的，而其它的已被使用。若用1表示分配单元已被使用，则空闲内存可以表示为：`11000011000000111001111110001111...`。

![Bitmap vs Free list](/images/operating_systems/memory_management/bitmap-vs-free-list.png)

分配单元的大小是一个很重要的设计因素。分配单元越小，位图越大。位图的大小同时取决于内存的大小和分配单元的大小。使用位图的主要问题是：在决定把一个占用`k`个分配单元的进程调入内存时，内存管理器必须搜索位图，在位图中找出`k`个连续的空闲块，这是一个很耗时的操作。

### 空闲链表

使用空闲链表时，需要维护一个记录已分配内存段和空闲内存段的链表，其中链表中的一个节点要么保护一个进程，要么表示两个进程间的空闲区。链表中的每一个节点都有节点标识(例如用`H(hole)`标识空闲，`P(process)`表示进程)、起始地址、长度和一个指向下一节点的指针。上图就展示了一个按地址顺序排列的单链表结构，有时候双向链表可能更合适。

当创建新进程或从硬盘换入的进程时，有几种算法可以为其分配内存：
* **首次适配（first fit）**：内存管理器从空闲链表头进行搜索，直到找到一个能够容纳下进程的空闲区，若空闲区大于进程所需内存的大小，则将空闲区分为两部分：一部分供进程使用，另一部分形成新的空闲区。首次适配算法的速度非常快，因为它尽可能少的搜索节点。
* **下次适配（next fit）**：工作方式和首次适配相同，不同点在于每次找到合适的空闲区后就记录当前位置，下次寻找空闲区时就从之前记录的位置开始搜索。
* **最佳适配（best fit）**：从头到尾搜索整个链表，找到能容纳进程的最小空闲区。因为要搜索整个链表，所以最佳适配算法的速度比较慢，而且容易产生大量无用的小空闲区。
* **最差适配（worst fit）**：最佳适配算法会产生很多非常小的空闲区，为了避免这一问题，最差适配算法总是给进程分配最大的可用空闲区，使新形成的空闲区较大而可以继续使用。
* **快速适配（quick fit）**：为常用大小的空闲区单独维护一个链表，这样一来，寻找一个指定大小的空闲区是十分迅速的。

## 虚拟内存

为了解决进程所需空间比物理内存大的这个问题，MMU 将一部分硬盘空间作为 RAM 的补充，形成
**虚拟内存（virtual memory）**。虚拟内存的基本思想是：每个程序都有自己的地址空间，这个地址空间被划分为了很多被称为 **页（page）** 的块。每一页都是一个连续的地址区间。页被映射到物理内存上面，运行程序并不需要所有的页都在物理内存中。当程序引用了其地址空间的某一部分时，若这一部分这物理内存内，则硬件执行必要的映射，否则操作系统需要将不在物理内存中的那一部分地址载入物理内存并重新执行失败的指令。

虚拟内存适合在多道程序设计系统中使用，同一时刻物理内存中存有多个程序的页，当一个程序等待其页面被载入内存时，CPU 可以被另一个进程使用。虚拟内存本质上是一个虚拟地址空间，硬盘上必须有一个该地址空间的完整副本。

## 页式管理

大部分虚拟内存系统中都会使用一种被称为 **分页（paging）** 的技术。虚拟地址空间被划分为若干固定大小的单元，这里的单元称为 **页（page）**。物理内存也被划分为若干固定大小的单元，不过组成物理内存的单元被称为 **页框（page frame）**。页和页框的大小通常是一样的。

虚拟地址是一种解决内存超载的方法，这意味着虚拟地址空间大于物理地址空间。也就是说，当页和页框的大小相同时，页的数量将多余页框的数量。也就意味着，有一部分页没有被映射到页框。当程序访问了一个未映射的页，即物理内存中没有该页对应的页框，就会发生 **页错误（page fault）**。这个时候，MMU会发出一个缺页中断，使 CPU 陷入操作系统，操作系统先将一个页框对应的页换出到硬盘，把需要访问的页从硬盘换入到这个页框中，修改映射关系，重新启动被中断的指令。

### 分页相关工作

操作系统在以下四段时间内需要做和分页有关的工作：进程创建时、进程执行时、发生页错误时和进程终止时。

当在分页系统中创建一个新进程时，操作系统必须决定出程序和数据所占的初始空间大小并为它们创建页表。操作系统需要在内存中为页表分配空间并初始化。当进程被换出时，页表不需要驻留在内存中，但是在进程运行时，页表必须在内存中。此外，操作系统还需要再硬盘上的交换分区中分配空间，以便页被换出时有地方存放。交换分区也必须用程序正文和数据初始化，以便新进程在启动中遇到页错误时可以载入需要的页。页表和交换分区的信息必须被记录在进程表中。

当进程被调度执行时，MMU 会被重置，TLB 会被清空，这样就清除了上一个进程的痕迹。新进程的页表成为当前页表。

当页错误发生时，操作系统必须读取硬件寄存器并找出导致错误的那个虚拟地址，然后计算出所需要的页并在硬盘上找到它。之后，操作系统需要为新页找到一个可用的页框并将新页放进去。最后，回退程序计数器，使它指向引起页错误的指令，并重新执行该指令。

当进程退出时，操作系统必须释放进程的页表、页和页在硬盘上所占用的空间。如果某些页是共享的，只有当使用这个页的最后一个进程终止时，才可以释放相应的空间。

### 页表

每个由CPU生成的虚拟地址被划分为两部分：一个 **页号（page number）** 和一个 **页偏移（page offset）**。如果虚拟地址空间的大小为 $ 2^m $ 并且页的大小为 $ 2^n $ 字节，那么虚拟地址的高`m-n`位就被用作页号，而虚拟地址的低`n`位被用作页偏移。因此，虚拟地址可以被表示成下面这样：

![Virtual Address](/images/operating_systems/memory_management/virtual-address.png)

页号被用来索引**页表（page table）**，以得到虚拟页对应的页框号，页偏移则为虚拟地址在对应页框中的位置。如下图所示，页表中包含了每个页框的起始地址，页框的起始地址加上偏移量就得到了物理地址。

![Paging hardware](/images/operating_systems/memory_management/paging-hardware.png "分页硬件")

MMU通过以下步骤来完成虚拟地址到物理地址的翻译：
1. 从虚拟地址中取出页号`p`并将其用作页表的索引。
2. 从页表中取得`p`对应的页框号`f`。
3. 将虚拟地址中的页号`p`替换为页框号`f`。

由于页偏移`d`没有被修改，所以页框号`f`和页偏移`d`就构成了真正的物理地址。

### 分页系统面临的问题

在任何分页系统中，都面临两个问题：
1. 虚拟地址到物理地址的映射必须非常快。
2. 如果虚拟地址空间很大，那么页表也会很大。

第一个问题是由于每次访问内存都需要进行虚拟地址到物理地址的映射，所有的指令最终都必须来自内存，并且很多指令也会访问内存中的操作数。也就是说：每条指令都至少需要访问一次或两次页表。

第二个问题和现代计算机使用的虚拟地址大小有关。对于一个32位的虚拟地址，假设页大小为4KB，将得到超过100万页，这意味着页表将包含超过100万个表项。如果每个页表项大小为4字节，每个进程就需要4MB的物理地址空间来存放页表。每个进程都需要有自己的页表，因为每个进程都有自己的虚拟地址空间。

大而快速的页映射需求成为了构建计算机的一个巨大约束。从概念上看，最简单的设计就是使用一组快速的 **硬件寄存器** 组成的单个页表，表中的每一项都对应一个虚拟页。当启动一个进程时，操作系统将该进程在内存中的页表的副本加载到这组寄存器中，之后进程运行期间就不再需要到内存中访问页表了。这个方法的优势在于简单，地址映射过程中也不需要访问内存。缺点是在页表很大时，代价高昂，多数情况下并不实用。此外，每次进程上下文切换时，都需要重新载入整个页表，性能低下。还有一种极端的方法就是将整个页表都保存在内存中。硬件只需要一个寄存器，寄存器中存放页表开始位置的指针。当进程发生上下文切换时，只需要重新装载这个寄存器。这种做法的缺点是：在每条指令执行期间，都需要访问一次或多次内存以读取页表，速度非常慢。

TLB 通过加快虚拟地址到物理地址的映射过程解决了映射速度慢的问题，而多级页表和反向页表提供了巨大虚拟地址空间的解决方案。

### TLB

为了加速完成地址映射，减少到内存访问页表的次数，**TLB(Translation Lookaside Buffer)** 出现了。它是一个小型的硬件设备，包含了少量页和页框的映射关系，可以让 MMU 在不访问内存的情况下完成虚拟地址到物理地址的映射。TLB 通常在 CPU 当中，它很小，其包含的表项数通常在 32 和 1024 之间。MMU 在收到 CPU 生成的虚拟地址后，会首先检查页号是否存在于 TLB 中，如果存在，就可以立马得到页框号。如果页号不在 TLB 中(发生 **TLB缺失（TLB miss）** )，就必须去访问内存中的页表，获取到页框号之后，再去访问内存。然后，将刚才所用的页号和页框号添加到 TLB 中，以便加速下次访问。如果 TLB 已经满了，就必须采用某种置换策略（比如 LRU）从 TLB 淘汰一个表项，并用新找到的页表项替换它。当 TLB 从页表加载时，所有的字段都来自于内存。

![Paging hardware with TLB](/images/operating_systems/memory_management/paging-hardware-with-tlb.png "带 TLB 的分页硬件")

TLB 的完整工作流程如下：

![The working of a TLB](/images/operating_systems/memory_management/the_working_of_a_tlb.png "TLB 的工作过程（图片来自维基百科）")

#### TLB 缓存映射

TLB 中的映射关系是一对一的，这种基于缓存行的映射方案主要有 3 种：

1. 全相联映射（Fully Associative Mapping）
2. 直接映射（Direct Mapping）
3. （n路）组相联映射（(n-way) Set-Associative Mapping）

相联（Associative）指的是缓存的键与值之间的映射范围。全相联映射中，一个键可以映射到所有值，而组相联映射中一个键仅可以映射到一组值。

若采用全相联映射实现 TLB，那么在根据页号查找页框号时，就需要遍历所有的缓存条目，在缓存条目较多时查询速度会下降，这种方案有着明显的性能缺陷。

直接映射有点类似于哈希函数，假设 TLB 有 64 个条目，那么通过 `page number % 64` 就可以直接计算出页框号的位置。但这种方式在缓存命中率方面又会有问题。当我们需要进行页置换时，只有唯一的页面可供选择（因为给定虚拟地址，页框就确定下来了），因为直接映射对各种页面置换算法很不友好。

若一个页号可以映射到多个（数量不太多）页框号，则可以有效避免全相联映射的性能问题，还能让高频使用的页框被保留下来，这就是组相联映射。例如，因特尔 i7 CPU 的 L1 TLB 采用 4-way 64 条目的设计，L2 TLB 则采用 8-way 1024 条目的设计。

### 大内存分页

#### 多级页表

如果我们有一个32位的虚拟地址空间，页大小为4KB，页表项大小为4B，那么即使程序所引用的只是虚拟地址空间中很小的一部分，也总是需要一个4MB($2^{32}\div2^{12}\times2^2=2^{22}$)的页表驻留在内存中。对于64位地址空间，问题将变的更加复杂。很明显，我们并不希望在内存中划出这么大一块连续的区域用来存储页表。多级页表的秘诀就在于：避免让整个页表一直驻留在内存中，尤其不应该保留那些用不上的页。

对于二级页表而言，页表本身也被分成了很多页。考虑一个32位的地址空间，若页大小为4KB，则虚拟地址被分成20位页号和12位页偏移。因为我们也对页表分页，所以页号进一步被划分为10位页号和10位页偏移。因此，虚拟地址可以表示成下面这样：

![Virtual Address](/images/operating_systems/memory_management/two-level-page-table-virtual-address.png)

在上面的虚拟地址中，`p1`索引外层页表，`p2`索引内层页表，`d`为页偏移。虚拟地址到物理地址的翻译过程如下：

![Address Translation for A Two-level Paging Architecture](/images/operating_systems/memory_management/address-translation-for-a-two-level-paging-architecture.png)

一级页表中的每个表项负责映射虚拟地址空间中一个4MB的块，而二级页表中的每个表项都负责映射一个4KB的虚拟内存页面。举个例子，假设有一个32位的虚拟地址0x00403004(十进制为4206596)，这个虚拟地址对应`p1=1, p2=3, d=4`。MMU首先使用`p1`来索引一级页表得到表项1，它对应地址`4M ~ 8M-1`(第1个4M块)。然后使用`p2`来索引二级页表得到表项2，它对应的虚拟地址范围是它所在4M块内的`12288 ~ 16383`(第3个4K块)，对应绝对地址`4206592 ~ 4210687`，，这个表项就含有虚拟地址0x00403004的页框号。

二级页表从两个方面减少了内存占用：
1. 如果一级页表中的某个表项是空的，那么相应的二级页表就根本不存在。
2. 只有一级页表才需要常驻内存，系统可以在需要时创建、换入或换出二级页表。只有最常使用的二级页表才需要缓存在主存中。

以上所说的二级页表可以扩充为三级、四级甚至更多级。级数越多，灵活性越大。

#### 哈希页表

对于32位的虚拟地址空间，多级页表可以工作得很好。但对于更大的虚拟地址空间，多级页表就不是一个好主意了，这个时候一般使用 **哈希页表（hashed page table）**。
哈希页表对虚拟页号进行哈希得到哈希值，哈希表中的每个表项都包括一个链表(解决哈希冲突)，链表的节点包含3个字段：虚拟页号、虚拟页号映射的页框号和指向下一节点的指针。

![Hashed page table](/images/operating_systems/memory_management/hashed-page-table.png)

算法首先将虚拟地址中的虚拟页号哈希到哈希表，然后将虚拟页号和哈希表中第一个元素的虚拟页号相比，若相同，则使用该元素中的页框号去生成物理地址，否则沿着链表继续搜索。

#### 反向页表

**反向页表（inverted page table）** 是多级页表的一个替代方案。反向页表中，每一个表项对应的是一个页框，而不再是页。如果说多级页表是为虚拟地址空间设计的，那么反向页表就是为物理地址空间设计的。反向页表中的每个表项都记录了该页框对应的虚拟页和拥有该虚拟页的进程的信息。因此，<u>系统中只有一个页表</u>，并且对于每个页框来说，只有一个表项和它对应。

![Inverted page table](/images/operating_systems/memory_management/inverted-page-table.png)

因为是所有进程公用一个页表，所以我们需要区分出不同进程，上图在查找页表时使用进程id。当需要访问内存时，内存子系统会使用进程id和虚拟页号来搜索页表，如果在表项`i`处找到了符合要求的信息，则使用`i`和`d`生成物理地址。若搜索失败，则说明这是一个非法的地址访问。

尽管反向页表节省了大量空间，但它也有严重的缺陷：从虚拟地址到物理地址的转换变得非常困难。当进程访问页面`p`时，硬件不能再通过将`p`作为页表索引来查找物理页框，而是必须搜索整个反向页表来查找满足要求的表项。此外，每个内存访问操作都需要进行一次搜索操作。

TLB能够帮助缓解方向页表的缺陷，如果TLB能够记录所有频繁访问的页，地址转换就可能变得像往常的页表一样快。但是当TLB未命中时，需要使用软件搜索整个反向页表，一个可行的方法是建立一张哈希表，用虚拟地址来哈希，将内存中具有相同哈希值的虚拟页链接在一个链表上。一旦新的页框号被找到，就更新TLB。

#### 大页表

若有一个进程需要 1G 的内存，而默认分页大小为 4K，这时该进程就需要 $1G / 4K = 262144$ 个页。即使是拥有 1024 个条目的 i7 L2 TLB 也会 $262144 / 1024 = 256$ 个页复用 1 个缓存行的情况，很容易冲突，这是可以考虑采用大内存分页（Large Page 或 Huge Page）。若操作系统提供 4M 大小的页，则只需要 256 个页，这能大大提高 TLB 的查询性能。Linux 内核至 2.6 版本起就提供了 [HugePage](https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt) 的功能，默认不开启。我们可以通过修改系统配置项来开启它，具体操作方法可以参考 Debian 的 [wiki](https://wiki.debian.org/Hugepages)。

### 页面置换算法

当缺页中断出现时，操作系统必须从内存中换出一个页，以便为即将调入的页腾出空间。如果被换出的页在驻留内存期间被修改过，则必须更新其在硬盘上的副本。但是如何选择要换出的页呢，不同的页面置换算法采用了不同的置换策略。TLB 作为页表的高速缓存，它应该尽可能地将未来使用频率最高的数据保留住，并换出未来使用频率最低的数据。

当我们访问缓存查找数据时，要么命中（Hit），要么缺失（Miss）。假设访问缓存的时间（延迟）是 `L`，访问缓存数据缺失的概率为 `M`，缺失的平均代价是 `C`（即缓存缺失后获取数据的平均时间），则缓存的平均响应时间为：

$$ (1 - M) \times L + M \times C = L + (C - L) \times M $$

`L` 通常是不会变的，它有缓存本身决定。所以，我们需要想办法降低 `C` 和 `M`，页面置换算法主要考虑的就是如何提高缓存命中率。

#### 最优页面置换算法

**最优（optimal, OPT）** 页面置换算法的思想是：考察每页接下来不被访问的时间，置换掉不被访问时间最长的那个页。

对固定数量的页框来说，最优页面置换算法能够保证最低的页错误率。该算法难以实现，因为算法需要知道页在未来的使用情况。

#### 最近未使用页面置换算法

**从概率上说，最近没有使用的数据，未来使用的概率会比最近经常使用的数据低。** 操作系统可以为每一页设置一个两个标志位：`R` 表示页最近的访问情况，`M` 表示页最近的修改情况，访问页时，将 `R` 位设为 1，修改页时，将 `M` 位设为 1。将出现 4 类组合：
* 00：未访问，未修改。
* 01：未访问，已修改。
* 10：已访问，未修改。
* 11：已访问，已修改。

**最近未使用（Not Recently Used, NRU）** 页面置换算法在发生页错误时，随机从 `RM` 值最小的页中选取一个淘汰。算法隐含的意思是：在最近一个时钟周期内，淘汰一个没有被访问但已修改的页比淘汰一个被频繁访问但未修改的页要好。

#### 先进先出页面置换算法

操作系统维护一个所有当前在内存中的页的链表，最新换入的页放在链表尾，而最早换入的页在链表头。当发生页错误时，**先进先出（First-In First-Out, FIFO）** 页面置换算法会淘汰链表头部的页面，并将新换入的页面放在链表尾。算法本身很简单，但没有利用到缓存的局部性原理，可能将经常使用的页换出。

#### 第二次机会页面置换算法

为了避免 FIFO 算法可能将常用页面换出这一问题，**第二次机会（second chance）** 算法检查最老页的 `R` 位，如果为 0（这个页面未被访问），立即换出；如果为1，就将R位的值重置为0，并将该页放到链表尾，修改载入时间使得它看起来就像是刚被加载到内存的一样，然后继续搜索，直到找到一个未访问（`R=0`）的页。若所有的页都被访问过，第二次机会算法就退化成了的 FIFO 算法，算法将把所有的页都访问一遍并在这个过程中重置 `R` 位，最终由回到第一个 `R` 位被重置的页，并将其淘汰，所以算法总是可以结束的。

#### 时钟页面置换算法

尽管第二次机会算法很合理，但它经常需要在链表中移动页，这一操作可能不是很有必要，还降低了效率。一个更好的办法是将所有的页都保存在一个类似于钟面的环形链表中，并用一个表针指向最老的页面。当发生页错误时，算法首先检查表针指向的页，根据该页的R位进行操作：若为0，则淘汰该页面，否则清除R位并向前移动表针，重复这个过程直到找到一个R位为0的页并将其换出。这就是 **时钟（clock）** 算法。

#### 最近最少使用页面置换算法

基于局部性原理，在前面几条指令中频繁使用的页很有可能在后面的几条指令中被使用。当发生页错误时，置换未使用时间最长的页，这就是 **最近最少使用（Least Recently Used, LRU）** 算法。和 NRU 相比，LRU 会考虑一个时间范围内的数据，数据的参考范围更大。LRU 的思想是：最近一段时间最少使用到的数据应该被淘汰，空间应该留给最近频繁使用的数据。

LRU 是一个不错的算法，主要的问题就是如何实现 LRU 算法。算法的实现可能需要硬件的支持，问题就在于如何快速找到最近最少使用的那个页。常见的实现有两种：
* **使用计数器**。为页表中的每个表项都关联一个上次使用时间（`time-of-use`）的字段和一个计数器（记录逻辑上页的上次访问时间）。当页被访问时，计数器加一，然后将计数器的值更新到对应的 `time-of-use` 中，这样我们可以换出 `time-of-use` 值最小的页。这种实现在每次访问内存时都需要在页表中搜索 LRU 页并修改该页的 `time-of-use` 值。
* **使用队列**。维护一个队列尝试取第一条指令时，将触发缺页中断，迫使操作系统将包含第一条指令的页装入到内存。由全局变量和栈引起的页错误通常也会接踵而至。一段时间后，进程需要的大部分页都在内存中了，进程开始在页错误发生频率较低的情况下运行。这个策略被称为**请求调页（demand paging）**，因为页是按需载入，而不是预先载入。

大部分进程在工作时都会表现出一种 **局部性访问（locality of reference）** 行为，即进程不会均匀地访问它的地址空间，访问往往是集中于一小部分页上。一个进程当前正在使用的页的集合被称为它的 **工作集（working set）**，如果整个工作集都在内存中，那么进程很少会遇到页错误。若内存太小而无法容纳整个工作集，进程在运行过程中就会遇到大量的页错误，进而减慢进程的运行速度。如果程序每执行几条指令就产生一个页错误，那么就称这个程序出现了**颠簸（trashing）**。

不少分页系统都会设法追踪进程的工作集，以确保进程的工作集在进程运行前就在内存中，这种方法被称为 **工作集模型（working set model）**，目的在于大大降低页错误率。在进程运行期预先载入其工作集也叫 **预先调页（prepaging）**，需要注意的是进程的工作集是随时间变化的。工作集算法的思想就是：当发生页错误时，淘汰一个不在工作集中的页，如果页表中所有的页都在工作集中，就淘汰生存时间最长的那个。

#### 工作集时钟页面置换算法

工作集算法其实是比较耗时的，因为当页错误发生时，可能需要扫描整个页表才能确定被淘汰的页。有一种改进的算法，它基于时钟算法，又使用了工作集信息，称为 **WSClock**。

也时钟算法一样，WSClock 也需要一个循环链表。一开始，链表是空的。当第一个页被载入后，它也被加到链表中。随着越来越多的页加入到链表，它们会形成一个环。依然使用一个表针指向最老的页面，当发生页错误时，首先检查表针指向的页，如果R位为1，说明该页最近被访问过，不适合被淘汰，于是将该页的R位重置，指针指向下一页；若R位位0，先检查这个页是否被修改，如果未被修改，置换它，否则表针继续前移(避免由于调度硬盘写操作引起的进程切换，因为内存中被修改过的页在换出前需要被同步回硬盘)，期望找到一个未访问且未修改的页。

## 段式管理

**段（segmentation）** 指一段固定长度的，连续的地址空间。例如将一个程序分为代码段、数据段、堆栈段等，每个段都是一个独立的地址空间。有两种类型的段：
1. **虚拟内存段（virtual memory segmentation）**：一个进程被划分为很多段，不需要所有的段同时处于内存中。
2. **简单段（simple segmentation）**：一个进程被划分为很多段，进程运行时所有的段都在内存中。

### 段表

**段表（segment table）** 被用来完成二维虚拟地址到一维物理地址的映射，每一个表项包含该段在内存中的起始物理地址和段的长度。CPU生成的逻辑地址由两部分组成：段号(`s`)和段偏移(`d`)。MMU使用段号查找段表，得到段的起始地址和段长，如果段偏移大于段长，则说明这是一个越界访问，将导致**段错误（segmentation fault）**；否则使用段在内存中的起始地址加上段偏移，得到物理地址。

![Segment Table](/images/operating_systems/memory_management/segment-table-address-translation.png)

## 页式管理 vs 段式管理

页式管理和段式管理的主要区别：

| 关键点 | 页式管理                                                     | 段式管理                         |
| ------ | ------------------------------------------------------------ | -------------------------------- |
| 大小   | 固定大小的页和页框，硬件决定                                 | 可变大小的段，使用者决定         |
| 碎片   | 可能产生内部碎片                                             | 可能产生外部碎片                 |
| 表     | MMU从页表得知页的位置和状态，速度比段表慢，但可以使用TLB加速 | 段表包含段ID和相关信息，比页表快 |

页式管理的优点：
1. 不会产生外部碎片。
2. 页框不需要是连续的。

页式管理的缺点：
1. 可能产生内部碎片。
2. 比段式管理更长的内存查找时间，不过可以通过TLB补救。

段式管理的优点：
1. 不会产生内部碎片。
2. 段表比页表小，因此更节省内存。
3. 段的平均大小通常比大多数页大，一个段可以存储更多的进程数据。
4. 比页式管理更小的开销。

段式管理的缺点：
1. 可能产生外部碎片。

### 段页式管理

一些现代计算机采用了 **段页式（segmented paging）** 的内存管理方案。主存先被划分为若干可变大小的段，每个段进一步被划分为若干固定大小的页。每个段包含一个页表，因此一个进程可能有多个页表。这个时候，一个虚拟地址又三部分组成：段号、段内页号和页偏移。当进行内存访问时，先通过段表找到对应的段，然后通过段内页表找到对应的页，最后根据页偏移找到物理地址。

## 参考资料

1. ANDREW S. TANENBAUM, HERBERT BOS. *Modern Operating Systems, 4th Edition*. Pearson, 2015.
2. Randal E. Bryant, David R. O’Hallaron. *Computer Systems: A Programmer's Perspective, 3th Edition*. Pearson, 2016.
3. Abraham Silberschatz, Greg Gagne, Peter B. Galvin. *Operating System Concepts, 10th Edition*. Wiley, 2018.
4. [Translation lookaside buffer](https://en.wikipedia.org/wiki/Translation_lookaside_buffer).
5. [Hugepages](https://wiki.debian.org/Hugepages).
